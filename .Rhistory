library(tidyverse)
library(tidyr)
# untidy data ----
temp_data_wide <- tribble(
~date, ~station1, ~station2,  ~station3,
"2023-10-01", 30.1, 29.8,  31.2,
"2023-11-01", 28.6, 29.1,  33.4,
"2023-12-01", 29.9, 28.5,  32.3
)
# make tidy ----
temp_data_long <- temp_data_wide |>
pivot_longer(cols = starts_with("station"),
names_to = "station_id",
values_to = "temp_c")
View(temp_data_wide)
View(temp_data_long)
library(here)
ggplot(penguins,
aes(x = bill_length_mm,
y = bill_depth_mm))
library(palmerpenguins)
install.packages(palmerpenguins)
library(palmerpenguins)
install.packages("palmerpenguins")
library(palmerpenguins)
ggplot(penguins,
aes(x = bill_length_mm,
y = bill_depth_mm))
ggplot(penguins,
aes(x = bill_length_mm,
y = bill_depth_mm)) +
geom_point()
# mapping color globally
ggplot(na.omit(penguins),
aes(x = bill_length_mm,
y = bill_depth_mm,
color = species)) +
geom_point() +
geom_smooth(method = "lm")
# mapping color locally
ggplot(na.omit(penguins),
aes(x = bill_length_mm,
y = bill_depth_mm,
color = species)) +
geom_point(aes(color = species)) +
geom_smooth()
# mapping color globally
ggplot(na.omit(penguins),
aes(x = bill_length_mm,
y = bill_depth_mm,
color = species)) +
geom_point() +
geom_smooth(method = "lm")
# mapping color locally
ggplot(na.omit(penguins),
aes(x = bill_length_mm,
y = bill_depth_mm,
color = species)) +
geom_point(aes(color = species)) +
geom_smooth()
# mapping color globally
ggplot(na.omit(penguins),
aes(x = bill_length_mm,
y = bill_depth_mm,
color = species)) +
geom_point() +
geom_smooth(method = "lm")
# mapping color locally
ggplot(na.omit(penguins),
aes(x = bill_length_mm,
y = bill_depth_mm,
color = species)) +
geom_point(aes(color = species)) +
geom_smooth(method = "lm")
ggplot(penguins,
aes(x = body_mass_g,
y = flipper_length_mm,
color = body_mass_g)) +
geom_point() +
scale_color_gradient(low = "#132B43", high = "#F7DD4C")
ggplot(penguins,
aes(x = species)) +
geom_bar
ggplot(penguins,
aes(x = species)) +
geom_bar()
penguins_summary <- penguins %>%
count(species)
View(penguins_summary)
ggplot(penguins_summary,
aes(x = species,
y = n)) +
geom_bar(stat = "identity")
ggplot(penguins,
aes(x = species,
y = after_stat(prop))) +
geom_bar()
ggplot(penguins,
aes(x = species)) +
geom_bar() +
coord_polar()
install.packages("chron") # for working with dates / times
install.packages("naniar") # tools for exploring & handing missing data
install.packages("tidytuesdayR") # used to download TidyTuesday data
install.packages("tidycensus") # an R package that allows users to interface with a select number of the US Census Bureauâ€™s data APIs and return tidyverse-ready data frames
install.packages("ggridges") # {ggplot2} extension for creating ridgeline plots
install.packages("gghighlight") # {ggplot2} extension for highlighting geoms
install.packages("ggbeeswarm") # {ggplot2} extension for creating categorical scatter (violin point) plots
install.packages("see") # {ggplot2} extension for model visualization (we'll be using it for it's geom, geom_violindot())
install.packages("scales") # provides the internal scaling infrastructure used by ggplot2, and gives you tools to override the default breaks, labels, transformations and palettes (installed automatically with {ggplot2} or {tidyverse})
cencusKEY = "520db2c4b48d0af32d80f2039c1bf42cc25c7276"
mko <- read_csv("https://portal.edirepository.org/nis/dataviewer?packageid=knb-lter-sbc.2007.17&entityid=02629ecc08a536972dec021f662428aa")
mko <- read.csv("https://portal.edirepository.org/nis/dataviewer?packageid=knb-lter-sbc.2007.17&entityid=02629ecc08a536972dec021f662428aa")
View(mko)
mko_clean <- mko |>
# keep only necessary columns ----
select(year, month, day, decimal_time, Temp_bot, Temp_top, Temp_mid) |>
# create datetime column (not totally necessary for our plots, but it can helpful to know how to do this!) ----
unite(date, year, month, day, sep = "-", remove = FALSE) |>
mutate(time = chron::times(decimal_time)) |>
unite(date_time, date, time, sep = " ") |>
# coerce data types ----
mutate(date_time = as.POSIXct(date_time, "%Y-%m-%d %H:%M:%S", tz = "GMT"), # see <https://www.neonscience.org/resources/learning-hub/tutorials/dc-convert-date-time-posix-r> for overview of POSIXct vs POSIXlt
year = as.factor(year),
month = as.factor(month),
day = as.numeric(day)) |>
# add month name by indexing the built-in `month.name` vector ----
mutate(month_name = as.factor(month.name[month])) |>
# replace 9999s with NAs ----
naniar::replace_with_na(replace = list(Temp_bot = 9999,
Temp_top = 9999,
Temp_mid = 9999)) |>
# select/reorder desired columns ----
select(date_time, year, month, day, month_name, Temp_bot, Temp_mid, Temp_top)
library(dplyr)
mko_clean <- mko |>
# keep only necessary columns ----
select(year, month, day, decimal_time, Temp_bot, Temp_top, Temp_mid) |>
# create datetime column (not totally necessary for our plots, but it can helpful to know how to do this!) ----
unite(date, year, month, day, sep = "-", remove = FALSE) |>
mutate(time = chron::times(decimal_time)) |>
unite(date_time, date, time, sep = " ") |>
# coerce data types ----
mutate(date_time = as.POSIXct(date_time, "%Y-%m-%d %H:%M:%S", tz = "GMT"), # see <https://www.neonscience.org/resources/learning-hub/tutorials/dc-convert-date-time-posix-r> for overview of POSIXct vs POSIXlt
year = as.factor(year),
month = as.factor(month),
day = as.numeric(day)) |>
# add month name by indexing the built-in `month.name` vector ----
mutate(month_name = as.factor(month.name[month])) |>
# replace 9999s with NAs ----
naniar::replace_with_na(replace = list(Temp_bot = 9999,
Temp_top = 9999,
Temp_mid = 9999)) |>
# select/reorder desired columns ----
select(date_time, year, month, day, month_name, Temp_bot, Temp_mid, Temp_top)
library(tidyverse)
library(chron)
library(naniar)
library(dplyr)
mko_clean <- mko |>
# keep only necessary columns ----
select(year, month, day, decimal_time, Temp_bot, Temp_top, Temp_mid) |>
# create datetime column (not totally necessary for our plots, but it can helpful to know how to do this!) ----
unite(date, year, month, day, sep = "-", remove = FALSE) |>
mutate(time = chron::times(decimal_time)) |>
unite(date_time, date, time, sep = " ") |>
# coerce data types ----
mutate(date_time = as.POSIXct(date_time, "%Y-%m-%d %H:%M:%S", tz = "GMT"), # see <https://www.neonscience.org/resources/learning-hub/tutorials/dc-convert-date-time-posix-r> for overview of POSIXct vs POSIXlt
year = as.factor(year),
month = as.factor(month),
day = as.numeric(day)) |>
# add month name by indexing the built-in `month.name` vector ----
mutate(month_name = as.factor(month.name[month])) |>
# replace 9999s with NAs ----
naniar::replace_with_na(replace = list(Temp_bot = 9999,
Temp_top = 9999,
Temp_mid = 9999)) |>
# select/reorder desired columns ----
select(date_time, year, month, day, month_name, Temp_bot, Temp_mid, Temp_top)
#......................explore missing data......................
# counts and percentage of missing data by year ----
see_NAs <- mko_clean |>
group_by(year) |>
naniar::miss_var_summary() |>
filter(variable == "Temp_bot")
# visualize missing Temp_bot ----
bottom <- mko_clean |> select(Temp_bot)
missing_temps <- naniar::vis_miss(bottom)
View(temp_data_wide)
mko_clean |>
mutate(month_name = factor(month_name, levels = month.name)) |>
ggplot(aes(x = Temp_bot, fill = month_name)) +
geom_histogram(position = "identity", alpha = 0.5)
mko_clean |>
mutate(month_name = factor(month_name, levels = month.name)) |>
ggplot(aes(x = Temp_bot)) +
geom_histogram() +
facet_wrap(~month_name)
mko_clean |>
mutate(month_name = factor(x = month_name, levels = month.name)) |>
ggplot(aes(x = Temp_bot, fill = month_name)) +
geom_density(alpha = 0.5)
mko_clean |>
mutate(month_name = factor(month_name, levels = month.name)) |>
ggplot(aes(x = Temp_bot)) +
geom_density(fill = "gray30") +
facet_wrap(~month_name)
mko_clean |>
mutate(month_name = factor(month_name, levels = month.name)) |>
ggplot(aes(x = Temp_bot)) +
geom_density(fill = "gray30") +
facet_wrap(~month_name)
dummy_data <- data.frame(value = c(rnorm(n = 100, mean = 5),
rnorm(n = 200, mean = 10)),
group = rep(c("A", "B"),
times = c(100, 200)))
ggplot(mko_clean, aes(x = Temp_bot, y = month_name)) +
ggridges::geom_density_ridges()
ggplot(mko_clean, aes(x = Temp_bot, y = month_name, fill = after_stat(x))) +
ggridges::geom_density_ridges_gradient() +
scale_fill_gradientn(colors = c("#2C5374","#849BB4", "#D9E7EC", "#EF8080", "#8B3A3A"))
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##                                    setup                                 ----
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#.........................load libraries.........................
library(tidycensus)
library(tidyverse)
library(janitor)
library(gghighlight)
#.........................source API key.........................
source(here::here("week3", "KEYS.R"))
print(here())
library(here)
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##                                    setup                                 ----
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#.........................load libraries.........................
library(tidycensus)
library(tidyverse)
library(janitor)
library(gghighlight)
library(here)
#.........................source API key.........................
source(here::here("week3", "KEYS.R"))
here()
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##                                    setup                                 ----
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#.........................load libraries.........................
library(tidycensus)
library(tidyverse)
library(janitor)
library(gghighlight)
library(here)
#.........................source API key.........................
source(here::here("week3", "KEYS.R"))
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##                                    setup                                 ----
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#.........................load libraries.........................
library(tidycensus)
library(tidyverse)
library(janitor)
library(gghighlight)
library(here)
#.........................source API key.........................
source(here::here("week-3", "KEYS.R"))
census_api_key(censusKEY)
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##                                    setup                                 ----
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#.........................load libraries.........................
library(tidycensus)
library(tidyverse)
library(janitor)
library(gghighlight)
library(here)
#.........................source API key.........................
source(here::here("week-3", "KEYS.R"))
census_api_key(censusKEY)
#..........................import data...........................
lyme <- read_csv(here::here("week-3", "data", "LD-Case-Counts-by-County-01-20.csv"))
#..........................import data...........................
lyme <- read_csv(here::here("week-3", "data", "LD-Case-Counts-by-County-01-20.csv"))
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##                                    setup                                 ----
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#.........................load libraries.........................
library(tidycensus)
library(tidyverse)
library(janitor)
library(gghighlight)
library(here)
#.........................source API key.........................
source(here::here("week-3", "KEYS.R"))
census_api_key(censusKEY)
#..........................import data...........................
lyme <- read_csv(here::here("week-3", "data", "LD-Case-Counts-by-County-01-20.csv"))
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##                          wrangle lyme disease data                       ----
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#............wide to long (plus some other wrangling)............
lyme_clean <- lyme |>
# make col names snake_case ----
janitor::clean_names() |>
# rename columns ----
rename(city = ctyname, state = stname, status = ststatus) |>
# wide to long (tidy) years
pivot_longer(cols = 6:25, names_to = "city_year", values_to = "reported_cases") |>
# remove "cases" from the year & coerce year from chr to factor ----
mutate(year = str_remove(city_year, pattern = "cases"),
year = as.factor(year)) |>
# select necessary cols ----
select(year, city, state, status, reported_cases)
#................calculate total cases per state.................
lyme_by_state <- lyme_clean |>
group_by(year, state) |>
summarize(total_cases = sum(reported_cases))
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##                      request / wrangle population data                   ----
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#...................get pop estimates by state...................
us_state_pop <- get_estimates(geography = "state",
product = "population",
state = NULL,
year = 2019) |>
filter(variable == "POP") |>
select(state = NAME, population = value)
#........................write data to csv.......................
# optional, but recommended in case you want to work offline, the API is down, etc. (you can then read in your saved data file rather than run the above code)
# write_csv(us_state_pop, file = here::here("week3", "data", "us_state_pop.csv"))
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##                            join lyme & pop dfs                           ----
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
lyme_pop <- left_join(lyme_by_state, us_state_pop) |>
# add col with num of 100k people per state ----
mutate(pop100k = population/100000) |>
# calculate num cases per 100k people (common way of reporting disease incidence) ----
mutate(cases_per100k = total_cases/pop100k)
View(us_state_pop)
install.packages("geofacet") # facet data for different geographical regions using panels arranged in shapes that mimic geographic topology
library(tidyverse)
library(tidyverse)
tuesdata <- tidytuesdayR::tt_load('2021-07-20')
drought <- tuesdata$drought
rm(list=ls())
tuesdata <- tidytuesdayR::tt_load('2021-07-20')
drought <- tuesdata$drought
View(drought)
plot1 <- ggplot() +
geom_violin(data = tuesdata, aes(x = drought_lvl, y = area_pct))
tuesdata <- tidytuesdayR::tt_load('2021-07-20')
drought <- tuesdata$drought
plot1 <- ggplot() +
geom_violin(data = drought, aes(x = drought_lvl, y = area_pct))
plot1
plot1 <- ggplot() +
geom_violin(data = drought, aes(x = drought_lvl, y = area_total))
plot1
unique(drought$state_abb)
ca <- drought %>%
filter(state_abb %in% "CA")
plot1 <- ggplot() +
geom_violin(data = ca, aes(x = drought_lvl, y = area_total))
plot1
ca <- drought %>%
filter(state_abb %in% "CA")
plot1 <- ggplot() +
geom_violin(data = ca, aes(x = drought_lvl, y = area_total)) +
geom_boxplot(data = ca, aes(x = drought_lvl, y = area_total))
plot1
ca <- drought %>%
filter(state_abb %in% "CA")
plot1 <- ggplot() +
geom_boxplot(data = ca, aes(x = drought_lvl, y = area_total)) +
geom_violin(data = ca, aes(x = drought_lvl, y = area_total))
plot1
ca <- drought %>%
filter(state_abb %in% "CA")
plot1 <- ggplot() +
geom_boxplot(data = ca, aes(x = drought_lvl, y = area_total)) +
geom_violin(data = ca, aes(x = drought_lvl, y = area_total), trim = FALSE) +
theme(
x =
)
ca <- drought %>%
filter(state_abb %in% "CA")
plot1 <- ggplot() +
geom_boxplot(data = ca, aes(x = drought_lvl, y = area_total)) +
geom_violin(data = ca, aes(x = drought_lvl, y = area_total), trim = FALSE)
plot1
ca <- drought %>%
filter(state_abb %in% "CA")
plot1 <- ggplot() +
geom_boxplot(data = ca, aes(x = drought_lvl, y = area_total)) +
geom_violin(data = ca, aes(x = drought_lvl, y = area_total))
plot1
?geom_violin
ca <- drought %>%
filter(state_abb %in% "CA")
plot1 <- ggplot() +
geom_boxplot(data = ca, aes(x = drought_lvl, y = area_total)) +
geom_violin(data = ca, aes(x = drought_lvl, y = area_total), trim = TRUE)
plot1
ca <- drought %>%
filter(state_abb %in% "CA")
plot1 <- ggplot() +
geom_boxplot(data = ca, aes(x = drought_lvl, y = area_total)) +
geom_violin(data = ca, aes(x = drought_lvl, y = area_total), trim = FALSE)
plot1
ca <- drought %>%
filter(state_abb %in% "CA")
plot1 <- ggplot() +
geom_boxplot(data = ca, aes(x = drought_lvl, y = area_total)) +
geom_violin(data = ca, aes(x = drought_lvl, y = area_total))
plot1
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##                            wrangle drought data                          ----
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
drought_clean <- drought |>
# select cols of interest & update names as needed ----
select(date = valid_start, state_abb, drought_lvl, area_pct) |>
# add year, month & day cols using {lubridate} fxns ----
mutate(year = year(date),
month = month(date, label = TRUE, abbr = TRUE),
day = day(date)) |>
# add drought level conditions names ----
mutate(drought_lvl_long = factor(drought_lvl,
levels = c("D4", "D3", "D2", "D1","D0", "None"),
labels = c("(D4) Exceptional", "(D3) Extreme",
"(D2) Severe", "(D1) Moderate", "(D0) Abnormally Dry",
"No Drought"))) |>
# reorder cols ----
select(date, year, month, day, state_abb, drought_lvl, drought_lvl_long, area_pct)
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##       create stacked area plot of CA drought conditions through time     ----
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
drought_clean |>
# remove drought_lvl "None" & filter for just CA ----
filter(drought_lvl != "None",
state_abb == "CA") |>
# create ggplot ----
ggplot(mapping = aes(x = date, y = area_pct, fill = drought_lvl_long)) +
# reverse order of groups so level D4 is closest to x-axis ----
geom_area(position = position_stack(reverse = TRUE)) +
# update colors to match US Drought Monitor (colors selected using ColorPick Eyedropper from original USDM data viz) ----
scale_fill_manual(values = c("#853904", "#FF0000", "#FFC100", "#FFD965", "#FFFF00")) +
# set x-axis breaks & remove padding between data and x-axis ----
scale_x_date(breaks = scales::breaks_pretty(n = 10),
expand = c(0, 0)) +
# set y-axis breaks & convert values to percentages & & remove padding between data and y-axis----
scale_y_continuous(breaks = seq(0, 100, by = 10),
labels = scales::label_percent(scale = 1),
expand = c(0, 0)) +
# add title ----
labs(title = "Drought area in California")
